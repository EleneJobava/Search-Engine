• 18:00–19:00: Did overall review of the assignment and analyzed the Json data structure, created project files
and folders. Confused about how combining name + description for search will work and whether they should be weighted
equally. No changes yet, still in planning phase.

• 19:00–20:00: Researched ranking approaches for search. Compared BM25 and sentence transformer based semantic search.
Was unsure whether BM25 alone would handle intent queries like "gift for kids" where no exact words match.
Decided to use both BM25 and semantic search combined into a hybrid score.
Implemented input preprocessing (lowercasing, removing special characters, trimming extra spaces).

• 21:00–22:00: Tried to understand how the semantic search actually works under the hood. Learned that embeddings are
just coordinates in high dimensional space where similar meanings land close together, even though they may not share
same letters. Once i understood embeddings cosine similarity followed naturally you are just measuring the angle
between two vectors. So with hybrid search BM25 will catch exact keyword matches, while semantic search will catch
meaning-based matches that share no words. Better to use together as BM25 wins on precise queries, semantics wins on
vague queries and can actually be worse at exact keyword matching. No changes made to the code.

• 11:00–15:00: Implemented the search function combining BM25 and semantic scores. Was confused about normalization
BM25 returns raw scores like 14.3 or 52.7 while semantic search returns cosine similarities already between
-1 and 1, so they're on completely different scales and can't be added directly. Learned that normalization means
rescaling BM25 scores to 0–1 range using min-max formula: (score - min) / (max - min). This way both scores are on
the same scale and can be combined with weights. Decided on 0.6 BM25 + 0.4 semantic since exact keyword matches matter
more in product search. Also handled the edge case where all BM25 scores are equal (max - min = 0) to avoid division
by zero.

• 15:00–15:30 : Added embedding cache to avoid re-encoding 10,000 products on every restart. Without caching startup took
60+ seconds which made development painful. Learned that numpy's np.save and np.load can persist the embedding matrix to
disk as a .npy file. Now on first run it encodes everything and saves to embeddings.npy, on subsequent runs it loads from
disk and starts instantly. Had to make sure the cache is invalidated if products change for now just delete the file
manually if the dataset changes.

• 16:00–17:00: Implemented the main FastAPI application. Decided on FastAPI over a CLI because it gives a real web interface
which is closer to a real online store experience. Set up a GET /search?q= endpoint which is cleaner than POST for search
queries since the query is just a parameter, not a request body. Served the frontend from a separate templates/index.html
file rather than embedding HTML in Python, cleaner separation of concerns.
Ran into a NotImplementedError because I was using the base BM25 class instead of BM25Okapi,fixed by changing the import.
Then hit a FileNotFoundError for the HTML template because the path ../templates/index.html was wrong uvicorn runs from
the project root so the correct path is templates/index.html. After fixing both errors the server started successfully.
Tested in the browser and confirmed search results display correctly with name, price, country, brand, and in-stock status.

• 17:00–18:00: Implemented tests for the search engine. Tested that exact keyword queries like "cotton t-shirt" return
relevant results. Tested case insensitivity "SAMEGRELO" should return identical results to "samegrelo".
Tested whitespace handling extra spaces should be normalized. Tested that messy input like "sameg@@relo" gets cleaned
correctly by handle_input even if the search results aren't perfect. Tested that results always return at most 10 items.
Confused initially about whether to test BM25 and semantic search separately or just the combined output decided testing
the final search() output is more useful since that's what the user actually sees. Did not mock the model since loading
it once for the test suite is acceptable.


• 19:00–20:00: Did final review of the project


